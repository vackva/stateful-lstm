{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import math\n",
    "\n",
    "from datetime import date, datetime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.163459700Z",
     "start_time": "2024-01-20T19:11:44.508826800Z"
    }
   },
   "id": "d80fc465400cc842"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "*This code is identically to the code found in the tensorflow training notebook*\n",
    "\n",
    "Basics:\n",
    " - provide a input and target audio file in the config\n",
    " - This will create 3 folders [train, val, test] in /Data which will be used for training\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4f57b51c451debb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def prepare_training_data(config):\n",
    "    in_rate, in_data = wavfile.read(config[\"input_audio_path\"])\n",
    "    out_rate, out_data = wavfile.read(config[\"target_audio_path\"])\n",
    "    \n",
    "    if len(in_data) != len(out_data):\n",
    "        print(\"input and target files have different lengths\")\n",
    "        sys.exit()\n",
    "      \n",
    "    if len(in_data.shape) > 1 or len(out_data.shape) > 1:\n",
    "        print(\"expected mono files\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Convert PCM16 to FP32\n",
    "    if in_data.dtype == \"int16\":\n",
    "        in_data = in_data / 32767\n",
    "        print(\"In data converted from PCM16 to FP32\")\n",
    "    if out_data.dtype == \"int16\":\n",
    "        out_data = out_data / 32767\n",
    "        print(\"Out data converted from PCM16 to FP32\")    \n",
    "\n",
    "    clean_data = in_data.astype(np.float32).flatten()\n",
    "    target_data = out_data.astype(np.float32).flatten()\n",
    "\n",
    "    # Split the data on a twenty percent mod\n",
    "    in_train, out_train, in_val, out_val = slice_on_mod(clean_data, target_data)\n",
    "\n",
    "    save_wav(config[\"output_path\"] + \"/train/\" + config[\"name\"] + \"-input.wav\", in_train)\n",
    "    save_wav(config[\"output_path\"] + \"/train/\" + config[\"name\"] + \"-target.wav\", out_train)\n",
    "\n",
    "    save_wav(config[\"output_path\"] + \"/test/\" + config[\"name\"] + \"-input.wav\", in_val)\n",
    "    save_wav(config[\"output_path\"] + \"/test/\" + config[\"name\"] + \"-target.wav\", out_val)\n",
    "\n",
    "    save_wav(config[\"output_path\"] + \"/val/\" + config[\"name\"] + \"-input.wav\", in_val)\n",
    "    save_wav(config[\"output_path\"] + \"/val/\" + config[\"name\"] + \"-target.wav\", out_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.182774800Z",
     "start_time": "2024-01-20T19:11:51.172266700Z"
    }
   },
   "id": "1cdc8701863f502b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def slice_on_mod(input_data, target_data, mod=5):\n",
    "    # Split the data on a modulus.\n",
    "\n",
    "    # Type cast to an integer the modulus\n",
    "    mod = int(mod)\n",
    "\n",
    "    # Split the data into 100 pieces\n",
    "    input_split = np.array_split(input_data, 100)\n",
    "    target_split = np.array_split(target_data, 100)\n",
    "\n",
    "    val_input_data = []\n",
    "    val_target_data = []\n",
    "    # Traverse the range of the indexes of the input signal reversed and pop every 5th for val\n",
    "    for i in reversed(range(len(input_split))):\n",
    "        if i % mod == 0:\n",
    "            # Store the validation data\n",
    "            val_input_data.append(input_split[i])\n",
    "            val_target_data.append(target_split[i])\n",
    "            # Remove the validation data from training\n",
    "            input_split.pop(i)\n",
    "            target_split.pop(i)\n",
    "\n",
    "    # Flatten val_data down to one dimension and concatenate\n",
    "    val_input_data = np.concatenate(val_input_data)\n",
    "    val_target_data = np.concatenate(val_target_data)\n",
    "\n",
    "    # Concatenate back together\n",
    "    training_input_data = np.concatenate(input_split)\n",
    "    training_target_data = np.concatenate(target_split)\n",
    "    return training_input_data, training_target_data, val_input_data, val_target_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.241064500Z",
     "start_time": "2024-01-20T19:11:51.184772Z"
    }
   },
   "id": "d2db02127a930a4c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def save_wav(name, data):\n",
    "    directory = os.path.dirname(name)\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    wavfile.write(name, 44100, data.flatten().astype(np.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.244068400Z",
     "start_time": "2024-01-20T19:11:51.199615300Z"
    }
   },
   "id": "8ac5a30c5ce341b1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In data converted from PCM16 to FP32\n",
      "Out data converted from PCM16 to FP32\n"
     ]
    }
   ],
   "source": [
    "importConfig = {\n",
    "    \"input_audio_path\": \"TrainingData/flanger-input.wav\",\n",
    "    \"target_audio_path\": \"TrainingData/flanger-target.wav\",\n",
    "    \"output_path\": \"Data\",\n",
    "    \"name\": \"flanger\"\n",
    "}\n",
    "\n",
    "prepare_training_data(importConfig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.270637500Z",
     "start_time": "2024-01-20T19:11:51.212811500Z"
    }
   },
   "id": "c7cc0b6f364b5692"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46db2dbe23cb7b1c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# converts numpy audio into frames, and creates a tf tensor from them, frame_len = 0 just converts to a tf tensor\n",
    "def framify(audio, frame_len):\n",
    "    # If audio is mono, add a dummy dimension\n",
    "    audio = np.expand_dims(audio, 1) if len(audio.shape) == 1 else audio\n",
    "        \n",
    "    # Calculate the number of segments\n",
    "    seg_num = math.floor(audio.shape[0] / frame_len) if frame_len else 1\n",
    "    \n",
    "    # Adjust frame_len if it's not provided\n",
    "    frame_len = audio.shape[0] if not frame_len else frame_len\n",
    "    \n",
    "    # Find the number of channels\n",
    "    channels = audio.shape[1]\n",
    "    \n",
    "    # Initialize tensor array\n",
    "    dataset = tf.TensorArray(dtype=tf.float32, size=seg_num)\n",
    "\n",
    "    # Populate the tensor array\n",
    "    for i in range(seg_num):\n",
    "        segment = tf.convert_to_tensor(audio[i * frame_len:(i + 1) * frame_len, :])\n",
    "        dataset = dataset.write(i, segment)\n",
    "\n",
    "    # Stack the tensor array\n",
    "    dataset = dataset.stack()  # Shape will be [seg_num, frame_len, channels]\n",
    "\n",
    "    # Reshape to [frame_len, seg_num, channels] if seg_num is the batch size\n",
    "    dataset = tf.reshape(dataset, [seg_num, frame_len, channels])\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.285246900Z",
     "start_time": "2024-01-20T19:11:51.244068400Z"
    }
   },
   "id": "eaa520556c46a674"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# The SubSet class holds a subset of data,\n",
    "# frame_len sets the length of audio per frame (in s), if set to 0 a single frame is used instead\n",
    "class SubSet:\n",
    "    def __init__(self, frame_len):\n",
    "        self.data = {}\n",
    "        self.frame_len = frame_len\n",
    "        self.conditioning = None\n",
    "        self.fs = None\n",
    "\n",
    "    def add_data(self, fs, audio, ext, cond_val):\n",
    "        if not self.fs:\n",
    "            self.fs = fs\n",
    "        assert self.fs == fs, \"data with different sample rate provided to subset\"\n",
    "        ext = 'data' if not ext else ext\n",
    "        framed_data = framify(audio, self.frame_len)\n",
    "\n",
    "        try:\n",
    "            data = list(self.data[ext])\n",
    "            self.data[ext] = (tf.concat([data[0], framed_data], axis=1),)\n",
    "        except KeyError:\n",
    "            self.data[ext] = (framed_data,)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.347042100Z",
     "start_time": "2024-01-20T19:11:51.260116400Z"
    }
   },
   "id": "590dbd9121fa8c3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, data_dir='../Dataset/', extensions=('input', 'target')):\n",
    "        self.extensions = extensions if extensions else ['']\n",
    "        self.subsets = {}\n",
    "        assert type(data_dir) == str, \"data_dir should be string,not %r\" % {type(data_dir)}\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    # add a subset called 'name', desired 'frame_len' is given in seconds, or 0 for just one long frame\n",
    "    def create_subset(self, name, frame_len=0):\n",
    "        assert type(name) == str, \"data subset name must be a string, not %r\" %{type(name)}\n",
    "        assert not (name in self.subsets), \"subset %r already exists\" %name\n",
    "        self.subsets[name] = SubSet(frame_len)\n",
    "\n",
    "    # load a file of 'filename' into existing subset/s 'set_names', split fractionally as specified by 'splits',\n",
    "    # if 'cond_val' is provided the conditioning value will be saved along with the frames of the loaded data\n",
    "    def load_file(self, filename, set_names='train', splits=None, cond_val=None):\n",
    "        # Assertions and checks\n",
    "        if type(set_names) == str:\n",
    "            set_names = [set_names]\n",
    "        assert len(set_names) == 1 or len(set_names) == len(splits), \"number of subset names must equal number of \" \\\n",
    "                                                                     \"split markers\"\n",
    "        assert [self.subsets.get(each) for each in set_names], \"set_names contains subsets that don't exist yet\"\n",
    "\n",
    "        # Load each of the 'extensions'\n",
    "        for i, ext in enumerate(self.extensions):\n",
    "            try:\n",
    "                file_loc = os.path.join(self.data_dir, filename + '-' + ext)\n",
    "                file_loc = file_loc + '.wav' if not file_loc.endswith('.wav') else file_loc\n",
    "                np_data = wavfile.read(file_loc)\n",
    "            except FileNotFoundError:\n",
    "                print([\"File Not Found At: \" + self.data_dir + filename])\n",
    "                return\n",
    "\n",
    "            raw_audio = np_data[1].astype(np.float32)\n",
    "\n",
    "            if len(set_names) == 1:\n",
    "                self.subsets[set_names[0]].add_data(np_data[0], raw_audio, ext, cond_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.362381400Z",
     "start_time": "2024-01-20T19:11:51.278639Z"
    }
   },
   "id": "8ba61202135c59f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f2ed6f6e582365"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class StatefulLSTM(tf.keras.Model):\n",
    "    def __init__(self, input_size=1, output_size=1, hidden_size=32, skip=1, bias_fl=True, batch_size=4096):\n",
    "        super(StatefulLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.skip = skip\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = keras.layers.LSTM(units=hidden_size, return_sequences=True, stateful=True, return_state=True, batch_size=batch_size)    \n",
    "        self.dense = keras.layers.Dense(units=output_size, activation=None, batch_size=batch_size, use_bias=bias_fl)\n",
    "        \n",
    "        # Build LSTM before training, because stateful lstm requires information batch size to build static graph\n",
    "        self.lstm.build((batch_size, input_size, 1))\n",
    "        \n",
    "    def call(self, x):\n",
    "        x, _, _ = self.lstm(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_hidden(self, batch_size):\n",
    "        self.lstm.reset_states()\n",
    "    \n",
    "    def train_epoch(self, input_data, target_data, loss_fcn, optim, bs, init_len=200, up_fr=1000):\n",
    "\n",
    "        # shuffle the segments at the start of the epoch\n",
    "        shuffle = tf.random.shuffle(tf.range(input_data.shape[0]))\n",
    "    \n",
    "        self.reset_hidden(bs)\n",
    "\n",
    "        # Iterate over the batches\n",
    "        ep_loss = 0\n",
    "        for batch_i in range(math.ceil(shuffle.shape[0] / bs)):            \n",
    "\n",
    "            # Use tf.gather to index the tensors\n",
    "            input_batch = tf.gather(input_data, shuffle[batch_i * bs:(batch_i + 1) * bs], axis=0)\n",
    "            target_batch = tf.gather(target_data, shuffle[batch_i * bs:(batch_i + 1) * bs], axis=0)\n",
    "            \n",
    "            # Initialise network hidden state by processing some samples then zero the gradient buffers\n",
    "            # For training processing eine Anfangssequenz, damit ein brauchbarer hidden state vorliegt\n",
    "            # Training startet erst nach! einem eingelaufen hidden state\n",
    "            self(input_batch[:, 0:init_len, :])\n",
    "        \n",
    "            start_i = init_len\n",
    "            batch_loss = 0\n",
    "            # Iterate over the remaining samples in the mini batch\n",
    "            for k in range(math.ceil((input_batch.shape[1] - init_len) / up_fr)):\n",
    "                \n",
    "                with tf.GradientTape() as g:\n",
    "                    # Process input batch with neural network    \n",
    "                    output = self(input_batch[:, start_i:start_i + up_fr, :])\n",
    "                    loss = loss_fcn(output, target_batch[:, start_i:start_i + up_fr, :])\n",
    "                    with g.stop_recording():\n",
    "                        dloss_dw = g.gradient(loss, self.trainable_variables)\n",
    "                        optim.apply_gradients(zip(dloss_dw, self.trainable_variables))\n",
    "                    g.reset()\n",
    "                        \n",
    "                print(f\"loss: {loss}\")\n",
    "\n",
    "                # Update the start index for the next iteration and add the loss to the batch_loss total\n",
    "                start_i += up_fr\n",
    "                batch_loss += loss\n",
    "\n",
    "            # Add the average batch loss to the epoch loss and reset the hidden states to zeros\n",
    "            ep_loss += batch_loss / (k + 1)\n",
    "        \n",
    "        return ep_loss / (batch_i + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.428718700Z",
     "start_time": "2024-01-20T19:11:51.297780100Z"
    }
   },
   "id": "860763dc7078f73d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a727e279e029592"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class ESRLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super(ESRLoss, self).__init__()\n",
    "        self.epsilon = 1e-5\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        energy = tf.reduce_mean(tf.square(y_true)) + self.epsilon\n",
    "        return loss / energy\n",
    "\n",
    "class DCLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super(DCLoss, self).__init__()\n",
    "        self.epsilon = 1e-5\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = tf.reduce_mean(tf.square(tf.reduce_mean(y_true, axis=0) - tf.reduce_mean(y_pred, axis=0)))\n",
    "        energy = tf.reduce_mean(tf.square(y_true)) + self.epsilon\n",
    "        return loss / energy\n",
    "\n",
    "class LossWrapper(tf.keras.losses.Loss):\n",
    "    def __init__(self, loss_weights):\n",
    "        super(LossWrapper, self).__init__()\n",
    "        # Map the loss names to their corresponding classes\n",
    "        loss_dict = {'ESR': ESRLoss, 'DC': DCLoss}\n",
    "        # Create instances of the loss functions\n",
    "        self.loss_functions = [loss_dict[key]() for key in [\"ESR\", \"DC\"]]\n",
    "        # Assign the weights\n",
    "        self.loss_factors = [loss_weights[key] for key in [\"ESR\", \"DC\"]]\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        total_loss = 0\n",
    "        for i, loss_function in enumerate(self.loss_functions):\n",
    "            total_loss += loss_function(y_true, y_pred) * self.loss_factors[i]\n",
    "        return total_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.448354Z",
     "start_time": "2024-01-20T19:11:51.434560400Z"
    }
   },
   "id": "cbd60e7e671135d4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_size\": 1, # Number of channels\n",
    "    \"output_size\": 1, # Number of channels\n",
    "    \"skip_con\": 0, # is there a skip connection for the input to the output\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 16,\n",
    "    \"init_length\": 200, # Number of sequence samples to process before starting weight updates\n",
    "    \"up_fr\": 1000, # For recurrent models, number of samples to run in between updating network weights\n",
    "    \"validation_f\": 1, # Validation Frequency (in epochs)\n",
    "    \"val_chunk\": 1000, #Number of sequence samples to process in n each chunk of validation\n",
    "    \"learning_rate\": 0.0005, \n",
    "    \"hidden_size\": 32,\n",
    "    \"loss_fcns\": {\"ESR\": 0.75, \"DC\": 0.25},\n",
    "    \"hardware_device\": \"flanger\",\n",
    "    \"save_location\": \"Results-PyTorch\",\n",
    "    \"export_json\": 1,\n",
    "    \"export_torchscript\": 1,\n",
    "    \"stateful_lstm\": 1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T19:11:51.477227Z",
     "start_time": "2024-01-20T19:11:51.447351700Z"
    }
   },
   "id": "1c0c26066b7bc449"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the physical devices available:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "These are the visible devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Creating Stateful LSTM\n",
      "Model: \"stateful_lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 multiple                  4352      \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch:  1\n",
      "loss: 280.5711669921875\n",
      "loss: 223.938720703125\n",
      "loss: 250.28607177734375\n",
      "loss: 256.096923828125\n",
      "loss: 240.67544555664062\n",
      "loss: 238.42738342285156\n",
      "loss: 153.2185516357422\n",
      "loss: 147.706298828125\n",
      "loss: 137.23568725585938\n",
      "loss: 165.2877197265625\n",
      "loss: 211.10382080078125\n",
      "loss: 229.32496643066406\n",
      "loss: 234.23605346679688\n",
      "loss: 179.79705810546875\n",
      "loss: 200.38058471679688\n",
      "loss: 229.6547088623047\n",
      "loss: 208.60488891601562\n",
      "loss: 201.0019989013672\n",
      "loss: 192.56753540039062\n",
      "loss: 189.10452270507812\n",
      "loss: 144.41824340820312\n",
      "loss: 103.06532287597656\n",
      "Epoch loss: tf.Tensor(200.75928, shape=(), dtype=float32)\n",
      "Epoch:  2\n",
      "loss: 152.46560668945312\n",
      "loss: 118.29134368896484\n",
      "loss: 131.76229858398438\n",
      "loss: 135.25418090820312\n",
      "loss: 129.51844787597656\n",
      "loss: 122.79339599609375\n",
      "loss: 84.68401336669922\n",
      "loss: 78.37461853027344\n",
      "loss: 72.27326965332031\n",
      "loss: 84.48388671875\n",
      "loss: 102.40992736816406\n",
      "loss: 104.85657501220703\n",
      "loss: 108.95612335205078\n",
      "loss: 81.54191589355469\n",
      "loss: 88.47529602050781\n",
      "loss: 101.87031555175781\n",
      "loss: 87.2447509765625\n",
      "loss: 83.86647033691406\n",
      "loss: 77.98707580566406\n",
      "loss: 81.31346130371094\n",
      "loss: 69.38192749023438\n",
      "loss: 49.69007873535156\n",
      "Epoch loss: tf.Tensor(97.61341, shape=(), dtype=float32)\n",
      "Epoch:  3\n",
      "loss: 62.35240936279297\n",
      "loss: 55.86290740966797\n",
      "loss: 63.438079833984375\n",
      "loss: 74.80099487304688\n",
      "loss: 69.18631744384766\n",
      "loss: 71.77236938476562\n",
      "loss: 73.40897369384766\n",
      "loss: 73.5052719116211\n",
      "loss: 56.426002502441406\n",
      "loss: 64.62869262695312\n",
      "loss: 71.3534927368164\n",
      "loss: 78.51399230957031\n",
      "loss: 82.92826843261719\n",
      "loss: 64.66011047363281\n",
      "loss: 68.60995483398438\n",
      "loss: 71.80562591552734\n",
      "loss: 61.65469741821289\n",
      "loss: 66.72837829589844\n",
      "loss: 66.36021423339844\n",
      "loss: 75.296142578125\n",
      "loss: 67.92888641357422\n",
      "loss: 49.23382568359375\n",
      "Epoch loss: tf.Tensor(67.74798, shape=(), dtype=float32)\n",
      "Epoch:  4\n",
      "loss: 61.68938064575195\n",
      "loss: 54.79359817504883\n",
      "loss: 62.86742401123047\n",
      "loss: 71.00762939453125\n",
      "loss: 67.3775634765625\n",
      "loss: 67.71101379394531\n",
      "loss: 65.15818786621094\n",
      "loss: 62.025665283203125\n",
      "loss: 51.127471923828125\n",
      "loss: 58.3221435546875\n",
      "loss: 65.86283874511719\n",
      "loss: 70.18843841552734\n",
      "loss: 76.85426330566406\n",
      "loss: 60.29505157470703\n",
      "loss: 65.08755493164062\n",
      "loss: 70.80433654785156\n",
      "loss: 61.548065185546875\n",
      "loss: 64.40142822265625\n",
      "loss: 63.155357360839844\n",
      "loss: 71.55982971191406\n",
      "loss: 66.36495971679688\n",
      "loss: 48.70725631713867\n",
      "Epoch loss: tf.Tensor(63.950436, shape=(), dtype=float32)\n",
      "Epoch:  5\n",
      "loss: 58.08073425292969\n",
      "loss: 53.702964782714844\n",
      "loss: 61.39854049682617\n",
      "loss: 68.7847671508789\n",
      "loss: 64.64813232421875\n",
      "loss: 65.28182220458984\n",
      "loss: 66.70404052734375\n",
      "loss: 63.32370376586914\n",
      "loss: 51.23081970214844\n",
      "loss: 57.03134536743164\n",
      "loss: 63.32859802246094\n",
      "loss: 66.47805786132812\n",
      "loss: 72.02996063232422\n",
      "loss: 57.615699768066406\n",
      "loss: 62.112098693847656\n",
      "loss: 68.23123931884766\n",
      "loss: 61.06713104248047\n",
      "loss: 62.96113967895508\n",
      "loss: 61.39276123046875\n",
      "loss: 68.16973876953125\n",
      "loss: 63.076744079589844\n",
      "loss: 46.29521179199219\n",
      "Epoch loss: tf.Tensor(61.952053, shape=(), dtype=float32)\n",
      "Epoch:  6\n",
      "loss: 55.5509033203125\n",
      "loss: 51.94672393798828\n",
      "loss: 59.79499053955078\n",
      "loss: 65.70783996582031\n",
      "loss: 62.87208557128906\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "result_parent_path = os.path.join(current_directory, config[\"save_location\"])\n",
    "os.makedirs(result_parent_path, exist_ok=True)\n",
    "result_path = os.path.join(result_parent_path, config[\"hardware_device\"])\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(config[\"save_location\"], config[\"hardware_device\"])\n",
    "    \n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(f\"These are the physical devices available:\\n{physical_devices}\")\n",
    "\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    print(f\"These are the visible devices:\\n{visible_devices}\")\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "print(\"Creating Stateful LSTM\")\n",
    "network = StatefulLSTM(input_size=config[\"input_size\"], \n",
    "                       output_size=config[\"output_size\"], \n",
    "                       hidden_size=config[\"hidden_size\"], \n",
    "                       skip=config[\"skip_con\"],\n",
    "                       batch_size=config[\"batch_size\"])\n",
    "\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"], weight_decay=1e-4, epsilon=1e-8)\n",
    "loss_functions = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "#loss_functions = LossWrapper(config[\"loss_fcns\"])\n",
    "\n",
    "network.compile(optimizer=optimiser, loss=loss_functions)\n",
    "network.build((config[\"batch_size\"],1,1))\n",
    "network.summary()        \n",
    "\n",
    "dataset = DataSet(data_dir='Data')\n",
    "dataset.create_subset('train', frame_len=22050)\n",
    "dataset.load_file(os.path.join('train', config[\"hardware_device\"]), 'train')\n",
    "\n",
    "dataset.create_subset('val')\n",
    "dataset.load_file(os.path.join('val', config[\"hardware_device\"]), 'val')   \n",
    "\n",
    "for epoch in range(1, config[\"epochs\"] + 1):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    \n",
    "    # Run 1 epoch of training\n",
    "    epoch_loss = network.train_epoch(dataset.subsets['train'].data['input'][0],\n",
    "                                     dataset.subsets['train'].data['target'][0],\n",
    "                                     loss_functions, optimiser, config['batch_size'], config['init_length'], config['up_fr'])\n",
    "\n",
    "    print(\"Epoch loss:\", epoch_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-20T19:11:54.337632900Z"
    }
   },
   "id": "cca470a4e37d92cd"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the physical devices available:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "These are the visible devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Creating Stateful LSTM\n",
      "Model: \"stateful_lstm_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               multiple                  4352      \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch:  1\n",
      "tf.Tensor([ 4 11  6  7  8 15 10 14 12 13  3  9  1  2  5  0], shape=(16,), dtype=int32)\n",
      "Iterate over the batches2\n",
      "(16, 22050, 1)\n",
      "(16, 22050, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21480\\3991722147.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m trainConfig = {\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[1;34m\"input_size\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;31m# Number of channels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;34m\"output_size\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;31m# Number of channels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;34m\"skip_con\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;31m# is there a skip connection for the input to the output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21480\\3559290865.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(config)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"epochs\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Epoch: \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[1;31m# Run 1 epoch of training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m         epoch_loss = network.train_epoch(dataset.subsets['train'].data['input'][0],\n\u001B[0m\u001B[0;32m     48\u001B[0m                                          \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubsets\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'train'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'target'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m                                          loss_functions, optimiser, config['batch_size'], config['init_length'], config['up_fr'])\n\u001B[0;32m     50\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21480\\4020323729.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, input_data, target_data, loss_fcn, optim, bs, init_len, up_fr)\u001B[0m\n\u001B[0;32m     49\u001B[0m             \u001B[1;31m# For training processing eine Anfangssequenz, damit ein brauchbarer hidden state vorliegt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m             \u001B[1;31m# Training startet erst nach! einem eingelaufen hidden state\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m             \u001B[0mstart_i\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minit_len\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    565\u001B[0m                 \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mcopied_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcopied_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    566\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    567\u001B[0m             \u001B[0mlayout_map_lib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_map_subclass_model_variable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_layout_map\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 569\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1157\u001B[0m                     )\n\u001B[0;32m   1158\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_saved_model_inputs_spec\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1159\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_save_spec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1161\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 158\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21480\\4020323729.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, input_tensor)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    552\u001B[0m             \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconstants\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_constants\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    553\u001B[0m         )\n\u001B[0;32m    554\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    555\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 556\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    557\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    558\u001B[0m         \u001B[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m         \u001B[1;31m# tensors, then add them to the inputs and temporarily modify the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1157\u001B[0m                     )\n\u001B[0;32m   1158\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_saved_model_inputs_spec\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1159\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_save_spec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1161\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 158\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, inputs, mask, training, initial_state)\u001B[0m\n\u001B[0;32m    737\u001B[0m                             \u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    738\u001B[0m                             \u001B[0mnew_h\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    739\u001B[0m                             \u001B[0mnew_c\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    740\u001B[0m                             \u001B[0mruntime\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 741\u001B[1;33m                         ) = standard_lstm(**normal_lstm_kwargs)\n\u001B[0m\u001B[0;32m    742\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    743\u001B[0m                     (\n\u001B[0;32m    744\u001B[0m                         \u001B[0mlast_output\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001B[0m\n\u001B[0;32m    977\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    978\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mo\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtanh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    979\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    980\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 981\u001B[1;33m     last_output, outputs, new_states = backend.rnn(\n\u001B[0m\u001B[0;32m    982\u001B[0m         \u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    983\u001B[0m         \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    984\u001B[0m         \u001B[1;33m[\u001B[0m\u001B[0minit_h\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minit_c\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 155\u001B[1;33m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1180\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_dispatch_handler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1181\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mOpDispatcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNOT_SUPPORTED\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1182\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1183\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1184\u001B[1;33m           \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\backend.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001B[0m\n\u001B[0;32m   5166\u001B[0m                     \u001B[0minitial_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflat_new_state\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5167\u001B[0m                 )\n\u001B[0;32m   5168\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_ta_t\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5169\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5170\u001B[1;33m             final_outputs = tf.compat.v1.while_loop(\n\u001B[0m\u001B[0;32m   5171\u001B[0m                 \u001B[0mbody\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_step\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5172\u001B[0m                 \u001B[0mloop_vars\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_ta\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstates\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5173\u001B[0m                 \u001B[1;33m**\u001B[0m\u001B[0mwhile_loop_kwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[0;32m    530\u001B[0m                                     return_same_structure)\n\u001B[0;32m    531\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mmaximum_iterations\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    533\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 534\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\backend.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(time, output_ta_t, *states)\u001B[0m\n\u001B[0;32m   5145\u001B[0m                     \u001B[0mTuple\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moutput_ta_t\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5146\u001B[0m                 \"\"\"\n\u001B[0;32m   5147\u001B[0m                 \u001B[0mcurrent_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mta\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mta\u001B[0m \u001B[1;32min\u001B[0m \u001B[0minput_ta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5148\u001B[0m                 \u001B[0mcurrent_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpack_sequence_as\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurrent_input\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5149\u001B[1;33m                 output, new_states = step_function(\n\u001B[0m\u001B[0;32m   5150\u001B[0m                     \u001B[0mcurrent_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstates\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconstants\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5151\u001B[0m                 )\n\u001B[0;32m   5152\u001B[0m                 \u001B[0mflat_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(cell_inputs, cell_states)\u001B[0m\n\u001B[0;32m    964\u001B[0m         \u001B[0mh_tm1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcell_states\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# previous memory state\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    965\u001B[0m         \u001B[0mc_tm1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcell_states\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# previous carry state\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    966\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    967\u001B[0m         \u001B[0mz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcell_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 968\u001B[1;33m         \u001B[0mz\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh_tm1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecurrent_kernel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    969\u001B[0m         \u001B[0mz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias_add\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    970\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    971\u001B[0m         \u001B[0mz0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mz1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mz2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mz3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 155\u001B[1;33m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m   1480\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1481\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1482\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1483\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1484\u001B[1;33m           \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 155\u001B[1;33m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1180\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_dispatch_handler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1181\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mOpDispatcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNOT_SUPPORTED\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1182\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1183\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1184\u001B[1;33m           \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   1833\u001B[0m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype_hint\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbase_dtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"y\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1834\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1835\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1836\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1837\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_v2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Code\\stateful-lstm\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m    493\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    494\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    495\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    496\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 497\u001B[1;33m       \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    498\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    499\u001B[0m       return add_v2_eager_fallback(\n\u001B[0;32m    500\u001B[0m           x, y, name=name, ctx=_ctx)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train(trainConfig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T16:07:35.496674800Z",
     "start_time": "2024-01-20T16:07:33.194989200Z"
    }
   },
   "id": "ddc03fcf5a2209c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
